{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self,num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(1,num_features,dtype=torch.float32, device=device)\n",
    "        self.bias = torch.zeros(1,dtype=torch.float32, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear = torch.add(torch.mm(x, self.weights.t()), self.bias).view(-1)\n",
    "        probas = self._sigmoid(linear)\n",
    "        return probas\n",
    "    \n",
    "    def backward(self, x, y , probas):\n",
    "        grad_loss_wrt_out = probas.view(-1) - y\n",
    "        grad_loss_wrt_w = torch.mm(x.t(), grad_loss_wrt_out.view(-1,1).t())\n",
    "        grad_loss_wrt_b = torch.sum(grad_loss_wrt_out)\n",
    "        return grad_loss_wrt_w, grad_loss_wrt_b\n",
    "    \n",
    "    def predict_labels(self,x):\n",
    "        probas = self.forward(x)\n",
    "        labels = torch.where(probas >= 0.5, 1 , 0)\n",
    "        return labels\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
